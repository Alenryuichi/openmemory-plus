# OpenMemory Plus - Full Stack Docker Compose
# å®Œæ•´ç‰ˆï¼šQdrant + Ollama + BGE-M3 + OpenMemory MCP
#
# ä½¿ç”¨æ–¹æ³•:
#   å¯åŠ¨: docker compose -f docker-compose.full.yml up -d
#   åœæ­¢: docker compose -f docker-compose.full.yml down
#   æ—¥å¿—: docker compose -f docker-compose.full.yml logs -f
#
# é…ç½® LLM Provider:
#   åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®å¯¹åº”çš„ API Key:
#   - DEEPSEEK_API_KEY (æ¨è)
#   - MINIMAX_API_KEY
#   - ZHIPU_API_KEY
#   - DASHSCOPE_API_KEY (é€šä¹‰åƒé—®)
#   - OPENAI_API_KEY

version: '3.8'

services:
  # Qdrant å‘é‡æ•°æ®åº“
  qdrant:
    image: qdrant/qdrant:latest
    container_name: openmemory-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/readyz"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Ollama - æœ¬åœ° LLM è¿è¡Œæ—¶ (ç”¨äº BGE-M3 åµŒå…¥)
  ollama:
    image: ollama/ollama:latest
    container_name: openmemory-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # BGE-M3 æ¨¡å‹åˆå§‹åŒ–å™¨
  bge-m3-init:
    image: ollama/ollama:latest
    container_name: openmemory-bge-init
    depends_on:
      ollama:
        condition: service_healthy
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "ğŸ”„ æ£€æŸ¥ BGE-M3 æ¨¡å‹..."
        if ollama list | grep -q "bge-m3"; then
          echo "âœ… BGE-M3 æ¨¡å‹å·²å­˜åœ¨"
        else
          echo "ğŸ“¥ ä¸‹è½½ BGE-M3 æ¨¡å‹ (çº¦ 1.2GB)..."
          ollama pull bge-m3
          echo "âœ… BGE-M3 æ¨¡å‹ä¸‹è½½å®Œæˆ"
        fi
    restart: "no"

  # OpenMemory MCP æœåŠ¡
  openmemory-mcp:
    image: mem0ai/openmemory-mcp:latest
    container_name: openmemory-mcp
    ports:
      - "8765:8765"
    volumes:
      # æŒ‚è½½ä¿®æ”¹åçš„ categorization.py ä»¥æ”¯æŒå¤š LLM Provider
      - ./patches/categorization.py:/app/app/utils/categorization.py:ro
    environment:
      # Qdrant é…ç½®
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      # Ollama é…ç½® (ç”¨äº embedding)
      - OLLAMA_HOST=http://ollama:11434
      - MEM0_EMBEDDING_MODEL=bge-m3
      - MEM0_EMBEDDING_PROVIDER=ollama
      # LLM Provider é…ç½® (ç”¨äºè®°å¿†åˆ†ç±»)
      # åªéœ€è®¾ç½®ä¸€ä¸ªï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY:-}
      - MINIMAX_API_KEY=${MINIMAX_API_KEY:-}
      - ZHIPU_API_KEY=${ZHIPU_API_KEY:-}
      - DASHSCOPE_API_KEY=${DASHSCOPE_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      # å¯é€‰: è‡ªå®šä¹‰æ¨¡å‹
      - LLM_MODEL=${LLM_MODEL:-}
    depends_on:
      qdrant:
        condition: service_healthy
      ollama:
        condition: service_healthy
      bge-m3-init:
        condition: service_completed_successfully
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8765/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

volumes:
  qdrant_data:
    name: openmemory-qdrant-data
  ollama_data:
    name: openmemory-ollama-data

networks:
  default:
    name: openmemory-network

