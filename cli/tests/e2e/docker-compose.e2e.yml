# OpenMemory Plus - Full E2E Test Environment
# å®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•ç¯å¢ƒï¼ŒåŒ…å«æ‰€æœ‰ä¾èµ–æœåŠ¡

services:
  # å‘é‡æ•°æ®åº“
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/readyz"]
      interval: 5s
      timeout: 5s
      retries: 10
    networks:
      - e2e-network

  # Ollama LLM æœåŠ¡
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 5s
      timeout: 10s
      retries: 20
    networks:
      - e2e-network

  # BGE-M3 æ¨¡å‹åˆå§‹åŒ–
  bge-m3-init:
    image: ollama/ollama:latest
    depends_on:
      ollama:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "ğŸ”¤ Pulling BGE-M3 model..."
        ollama pull bge-m3
        echo "âœ… BGE-M3 model ready"
    environment:
      - OLLAMA_HOST=http://ollama:11434
    networks:
      - e2e-network

  # CLI æµ‹è¯•å®¹å™¨
  cli-test:
    build:
      context: ../../..
      dockerfile: cli/tests/e2e/Dockerfile.e2e
    depends_on:
      qdrant:
        condition: service_healthy
      ollama:
        condition: service_healthy
      bge-m3-init:
        condition: service_completed_successfully
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - OLLAMA_HOST=http://ollama:11434
    networks:
      - e2e-network
    volumes:
      - test-project:/workspace/test-project

networks:
  e2e-network:
    driver: bridge

volumes:
  ollama-data:
  test-project:

