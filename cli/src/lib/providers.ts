/**
 * LLM Provider Configuration
 * æ”¯æŒå¤šç§ LLM Provider ç”¨äºè®°å¿†åˆ†ç±»åŠŸèƒ½
 */

export interface LlmProvider {
  name: string;
  displayName: string;
  baseUrl: string;
  defaultModel: string;
  envKey: string;
  supportsStructuredOutput: boolean;
  description: string;
}

export const LLM_PROVIDERS: Record<string, LlmProvider> = {
  deepseek: {
    name: 'deepseek',
    displayName: 'DeepSeek',
    baseUrl: 'https://api.deepseek.com',
    defaultModel: 'deepseek-chat',
    envKey: 'DEEPSEEK_API_KEY',
    supportsStructuredOutput: false,
    description: 'æ€§ä»·æ¯”é«˜ï¼Œä¸­æ–‡èƒ½åŠ›å¼º',
  },
  minimax: {
    name: 'minimax',
    displayName: 'MiniMax',
    baseUrl: 'https://api.minimax.chat/v1',
    defaultModel: 'abab6.5s-chat',
    envKey: 'MINIMAX_API_KEY',
    supportsStructuredOutput: false,
    description: 'å›½äº§å¤§æ¨¡å‹ï¼Œå“åº”å¿«é€Ÿ',
  },
  zhipu: {
    name: 'zhipu',
    displayName: 'æ™ºè°± AI (ZhiPu)',
    baseUrl: 'https://open.bigmodel.cn/api/paas/v4',
    defaultModel: 'glm-4-flash',
    envKey: 'ZHIPU_API_KEY',
    supportsStructuredOutput: false,
    description: 'GLM ç³»åˆ—ï¼Œå­¦æœ¯èƒŒæ™¯',
  },
  qwen: {
    name: 'qwen',
    displayName: 'é€šä¹‰åƒé—® (Qwen)',
    baseUrl: 'https://dashscope.aliyuncs.com/compatible-mode/v1',
    defaultModel: 'qwen-turbo',
    envKey: 'DASHSCOPE_API_KEY',
    supportsStructuredOutput: false,
    description: 'é˜¿é‡Œäº‘ï¼Œç”Ÿæ€å®Œå–„',
  },
  openai: {
    name: 'openai',
    displayName: 'OpenAI',
    baseUrl: 'https://api.openai.com/v1',
    defaultModel: 'gpt-4o-mini',
    envKey: 'OPENAI_API_KEY',
    supportsStructuredOutput: true,
    description: 'åŸç‰ˆ GPTï¼ŒåŠŸèƒ½æœ€å…¨',
  },
  ollama: {
    name: 'ollama',
    displayName: 'Ollama (æœ¬åœ°)',
    baseUrl: 'http://localhost:11434/v1',
    defaultModel: 'qwen2.5:7b',
    envKey: '',
    supportsStructuredOutput: false,
    description: 'æœ¬åœ°è¿è¡Œï¼Œæ— éœ€ API Key',
  },
};

// Provider icons for display
const PROVIDER_ICONS: Record<string, string> = {
  deepseek: 'ğŸš€',
  minimax: 'ğŸ¤–',
  zhipu: 'ğŸ§ ',
  qwen: 'â˜ï¸',
  openai: 'ğŸŒ',
  ollama: 'ğŸ’»',
};

// L1 Fix: Auto-generate PROVIDER_CHOICES from LLM_PROVIDERS
export const PROVIDER_CHOICES = Object.entries(LLM_PROVIDERS).map(([key, provider]) => {
  const icon = PROVIDER_ICONS[key] || 'ğŸ“¦';
  const recommended = key === 'deepseek' ? ' (æ¨è)' : '';
  return {
    name: `${icon} ${provider.displayName}${recommended} - ${provider.description}`,
    value: key,
  };
});

/**
 * ç”Ÿæˆ Provider çš„ç¯å¢ƒå˜é‡é…ç½®
 */
export function generateProviderEnv(
  providerName: string,
  apiKey?: string
): Record<string, string> {
  const provider = LLM_PROVIDERS[providerName];
  if (!provider) return {};

  const env: Record<string, string> = {};

  // æ·»åŠ  API Key (å¦‚æœæœ‰)
  if (provider.envKey && apiKey) {
    env[provider.envKey] = apiKey;
  }

  // æ·»åŠ  base URL (å¦‚æœä¸æ˜¯é»˜è®¤çš„ OpenAIï¼Œä¸”æœ‰ envKey)
  // H4 Fix: è·³è¿‡ Ollama (envKey ä¸ºç©º)
  if (provider.baseUrl && providerName !== 'openai' && provider.envKey) {
    const baseUrlKey = provider.envKey.replace('_API_KEY', '_BASE_URL');
    env[baseUrlKey] = provider.baseUrl;
  }

  // æ·»åŠ æ¨¡å‹é…ç½®
  env['LLM_MODEL'] = provider.defaultModel;
  env['LLM_PROVIDER'] = providerName;

  return env;
}

/**
 * è·å– MCP é…ç½®ä¸­éœ€è¦çš„ç¯å¢ƒå˜é‡
 */
export function getMcpEnvForProvider(
  providerName: string,
  apiKey?: string
): Record<string, string> {
  const provider = LLM_PROVIDERS[providerName];
  if (!provider) return {};

  const env: Record<string, string> = {
    MEM0_EMBEDDING_MODEL: 'bge-m3',
    MEM0_EMBEDDING_PROVIDER: 'ollama',
    OLLAMA_HOST: 'http://localhost:11434',
    QDRANT_HOST: 'localhost',
    QDRANT_PORT: '6333',
  };

  if (provider.envKey && apiKey) {
    env[provider.envKey] = apiKey;
  }

  if (provider.baseUrl && providerName !== 'openai') {
    // ä½¿ç”¨ OPENAI_BASE_URL ä½œä¸ºé€šç”¨çš„ base URL é…ç½®
    env['OPENAI_BASE_URL'] = provider.baseUrl;
    // åŒæ—¶è®¾ç½® provider ç‰¹å®šçš„ key
    if (apiKey) {
      env['OPENAI_API_KEY'] = apiKey;
    }
  }

  return env;
}

/**
 * L2 Fix: Validate API Key by making a test request
 * Returns { valid: true } or { valid: false, error: string }
 */
export async function validateApiKey(
  providerName: string,
  apiKey: string
): Promise<{ valid: boolean; error?: string }> {
  const provider = LLM_PROVIDERS[providerName];
  if (!provider) {
    return { valid: false, error: 'æœªçŸ¥çš„ Provider' };
  }

  // Ollama doesn't need API key validation
  if (providerName === 'ollama') {
    return { valid: true };
  }

  try {
    const baseUrl = provider.baseUrl || 'https://api.openai.com/v1';
    const response = await fetch(`${baseUrl}/models`, {
      method: 'GET',
      headers: {
        Authorization: `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      signal: AbortSignal.timeout(10000), // 10 second timeout
    });

    if (response.ok) {
      return { valid: true };
    }

    // Handle common error codes
    if (response.status === 401) {
      return { valid: false, error: 'API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ' };
    }
    if (response.status === 403) {
      return { valid: false, error: 'API Key æƒé™ä¸è¶³' };
    }
    if (response.status === 429) {
      // Rate limited but key is valid
      return { valid: true };
    }

    return { valid: false, error: `HTTP ${response.status}: ${response.statusText}` };
  } catch (error) {
    const message = error instanceof Error ? error.message : String(error);
    if (message.includes('timeout') || message.includes('TimeoutError')) {
      return { valid: false, error: 'è¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ' };
    }
    if (message.includes('fetch') || message.includes('network')) {
      return { valid: false, error: 'ç½‘ç»œé”™è¯¯ï¼Œæ— æ³•è¿æ¥åˆ° API' };
    }
    return { valid: false, error: message };
  }
}
